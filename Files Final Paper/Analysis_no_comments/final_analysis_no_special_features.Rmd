---
title: "Data Analysis for Give me Gestalt - Cubist Art Experiment"
output: pdf_document
Authors: Group 03
---

# Instructions

## Required R packages
* `tidyverse` (or `ggplot2`, `dplyr`, `purrr`, `tibble`)
* `brms`
* `devtools` (for installing `faintr`)
* `rstan`
* `faintr` (install with `devtools`)

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = F, message = F)

```

Load the required packages and set a seed for the random number generator.
```{r}
library(tidyverse)

library(rstan)
# set cores to use to the total number of cores (minimally 4)
options(mc.cores = max(parallel::detectCores(), 4))
# save a compiled version of the Stan model file
rstan_options(auto_write = TRUE)

library(brms)

# install faintr with devtools::install_github('michael-franke/bayes_mixed_regression_tutorial/faintr', build_vignettes = TRUE))
library(faintr)

set.seed(123)

```

Step 1. Read the data and take a glimpse of it.
---

```{r}
data_raw <- read_csv("results_71_givemegestalt_group3_group3.csv")
glimpse(data_raw)
```


Step 2. Select only the columns of interest and filter trials that are not interesting for the calculations.
Change data type of the responses to double and submission_id to factor. Detect outliers.
---

```{r}
data_selection <- select(data_raw, submission_id, snellen_result, is_expert, age, gender, trial_name, trial_number, fileID, response, RT, timeSpent, comments)
data_filtered <- filter(data_selection, trial_name != "test_snellen", trial_name != "b0_expert")
data_mut <- mutate(data_filtered, response = as.double(response), submission_id = factor(submission_id))

show(data_selection)
show(data_filtered)
show(data_mut)

# 3 participants only rated "1" in both blocks, one participant only rated "7", one gave a invalid input for the Snellen test, we exclude them:
data_clean <- filter(data_mut, submission_id != 607, submission_id != 736, submission_id != 475, submission_id != 480, submission_id != 726)
show(data_clean)
```
Demografics
---
```{r}
data_rawdemografics <- select(data_clean, submission_id, age, gender, is_expert, snellen_result, comments)
data_demografics <- dplyr::distinct(group_by(data_rawdemografics, submission_id))
show(data_demografics[order(data_demografics$submission_id),])
```

Total number of participents:
```{r}
length(unique(data_clean$submission_id))
```
Detecting the gender data provided and their count:
```{r}
data_gender_male <- filter(data_clean,gender == "male")
data_gender_female <- filter(data_clean,gender == "female")
data_gender_diverse <- filter(data_clean,gender == "divers")
length(data_gender_male$gender)/120
length(data_gender_female$gender)/120
length(data_gender_diverse$gender)/120
sum(is.na(data_clean$gender))/120 # counting how many NA are there.
```
There are total 33 male participents, 58 female and 2 of them identify teir gender as diverse and 2 of them did not submitted the data about gender.

Data set according to age :
```{r}
data_age_below_20 <- filter(data_clean,age <= 19)
data_age_20_40<-filter(data_clean,age>=20&age<=40)
data_age_ab_40 <- filter(data_clean,age > 40)
#divide by 122 beacuse there are 122 entries per person
length(data_age_below_20$age)/120 
length(data_age_20_40$age)/120
length(data_age_ab_40$age)/120
sum(is.na(data_clean$age))/120
```
From total participants there are total 14 participants, who are below age of 20, 70 are in range of 20 - 40 and 10 are in range of 41 to 63. 1 participants did not give data for age.

Step 3. Filter participants with special features as being an expert or having failed the vision test.
Split data according to trial (b1: Liking, b2: Detactability).
---

```{r}
# Data without special groups
data_normal <- filter(data_clean, is_expert == "No", snellen_result > 6)
b1_normal <- filter(data_normal, trial_name == "b1_exp")
b2_normal <- filter(data_normal, trial_name == "b2_exp")

show(b1_normal)
show(b2_normal)
```

Step 4. Average data.
Generate table with needed non-aggregated data in useful format.
        
---

Data of participants without special features (snellen failed, expert)
```{r}
# Averaged data:
b1_normal_mean <- group_by(b1_normal, fileID) %>% summarise(mean_Like_normal = mean(response))
b2_normal_mean <- group_by(b2_normal, fileID) %>% summarise(mean_Detect_normal = mean(response))

show(b1_normal_mean)
show(b2_normal_mean)

final_normal_mean <- merge(x = b2_normal_mean, y = b1_normal_mean, by = "fileID")
show(final_normal_mean)

# Non-average data:
b1_normal_mutated <- mutate(b1_normal, liking_normal = response, RT_liking = RT)
b2_normal_mutated <- mutate(b2_normal, detectability_normal = response, RT_detectability = RT)

b1_normal_selected <- select(b1_normal_mutated, fileID, submission_id, age, snellen_result, timeSpent, liking_normal, RT_liking)
b2_normal_selected <- select(b2_normal_mutated, fileID, submission_id, age, snellen_result, timeSpent, detectability_normal, RT_detectability)

b1_normal_orderd <- b1_normal_selected[order(b1_normal_selected$fileID),]
b2_normal_orderd <- b2_normal_selected[order(b2_normal_selected$fileID),]

merged_normal_data <- b1_normal_orderd
merged_normal_data$detectability_normal <- b2_normal_orderd$detectability_normal
merged_normal_data$RT_detectability <- b2_normal_orderd$RT_detectability

show(b1_normal_selected)
show(b2_normal_selected)
show(b1_normal_orderd)
show(b2_normal_orderd)
show(merged_normal_data)

final_normal <- as_tibble(merged_normal_data)
show(final_normal)

```

Step 5.Test assumptions for linear regression.
---
Normality: participants without special features
```{r}
# Non-averaged data:
ks.test(b1_normal$response, pnorm)
ks.test(b2_normal$response, pnorm)

# Averaged data:
ks.test(b1_normal_mean$mean_Like_normal, pnorm)
ks.test(b2_normal_mean$mean_Detect_normal, pnorm)
```
Result: According to the Kolmogorov-Smirnov test the variables are not normal distributed. Hence, the normality assumption is not fullfiled. We will test the residual distribution in the next step to make sure that we can still use a linear regression.

Further assumptions: participants without special features
```{r}
# Non-averaged data:
hist(final_normal$liking_normal)
hist(final_normal$detectability_normal)
par(mfrow=c(2,2))
typeof(final_normal)

mod_normal <- lm(final_normal$liking_normal ~ final_normal$detectability_normal, data=final_normal) #linear regression model
gvlma::gvlma(mod_normal) # further tests for assumtions

summary(mod_normal) # Show summary to check p-value
plot(resid(mod_normal)) # Plot residuals to check if normality assumption is necessary
```
Result: For the non-averaged data, most of the assumptions necessary for linear-regression are not satisfied. Eventhough the violation of the normality assumtion is not important due to the huge sample size and the destribution of the residuals (https://iovs.arvojournals.org/article.aspx?articleid=2128171), we cannot use a linear regression for this data. 

```{r}
# Averaged data:
show(b1_normal_mean)
hist(b1_normal_mean$mean_Like_normal)
hist(b2_normal_mean$mean_Detect_normal)
par(mfrow=c(2,2))
typeof(b1_normal_mean)

mod_mean_normal <- lm(b1_normal_mean$mean_Like_normal ~ b2_normal_mean$mean_Detect_normal, data=final_normal_mean) # linear regression model
gvlma::gvlma(mod_mean_normal) # further tests for assumtions

summary(mod_mean_normal) # Show summary to check p-value
plot(resid(mod_mean_normal)) # Plot residuals to check if normality assumption is necessary
abline(a=0,b=0)
```
Result: Most of the assumptions for linear regression are satisfied. The distribution of the residuals shows asymmetry along the zero line, but not enough to violate the normality assumption. The p-value shows us that our model is significant. The R-squared value is lower than in the original paper.

Step 6. Make a plot of the averaged data.
---
Participants without special features:
```{r}
cor(b2_normal_mean$mean_Detect_normal, b1_normal_mean$mean_Like_normal)
scatter.smooth(y=b1_normal_mean$mean_Like_normal, x= b2_normal_mean$mean_Detect_normal, xlab = "Means Detection Scores", ylab = "Means Liking Scores")
ggplot(final_normal_mean, aes(x = mean_Detect_normal, y = mean_Like_normal)) + geom_point() + geom_smooth(method = "lm")

```
Results: The correlation between the two variables Liking and Detectability is positive, but lower than in the original experiment and lower than for all participants.
The lower R-squared value can be explained by outliers.

Step 7. Run bayesian fixed-effects models
---
Averaged Data:
```{r}
brm_normal_gaussian <- brm(formula=mean_Like_normal ~ mean_Detect_normal, data=final_normal_mean, family = "gaussian")
summary(brm_normal_gaussian)
```
Result: Positiv correltion, since estimate is 0.28.

Non-Averaged data:
Cumulative family:
```{r}
final_normal_mutated <- mutate(final_normal, liking_normal = as.integer(liking_normal), detectability_normal = as.integer(detectability_normal))
show(final_normal_mutated)

brm_normal_cumulative <- brm(formula=liking_normal ~ mo(detectability_normal), data=final_normal_mutated, family = "cumulative")
summary(brm_normal_cumulative)
```
Result: positive correlation, estimate is 0.34.

Cumulative family for mixed/random effects:
```{r}
brm_normal_mixed <- brm(formula=liking_normal ~ mo(detectability_normal) + (1|submission_id), data=final_normal_mutated, family = "cumulative")
summary(brm_normal_mixed)
```

```{r}
brm_normal_mixed2 <- brm(formula=liking_normal ~ mo(detectability_normal) + (1|submission_id) + (1|fileID), data=final_normal_mutated, family = "cumulative")
summary(brm_normal_mixed2)
```

Step 8. Compare different bmr models.
---
```{r}

loo(brm_normal_cumulative, brm_normal_mixed)

```

```{r}

loo(brm_normal_cumulative, brm_normal_mixed2)

```

```{r}

loo(brm_normal_mixed, brm_normal_mixed2)

```


```{r}
marginal_effects(brm_normal_gaussian)
marginal_effects(brm_normal_cumulative)

marginal_effects(brm_normal_mixed)
marginal_effects(brm_normal_mixed2)

```
